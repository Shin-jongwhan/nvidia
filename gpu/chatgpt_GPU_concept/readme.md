# GPU concept
### chatGPT에게 GPU가 작동하는 원리에 대해 물어보았다.
### https://chatgpt.com/share/6734553a-bfe0-800b-ab2c-5a8952f6832a
### <br/><br/>

## 질문 사
- 비용적인 측면에서, AWS에서 AMI를 별도로 만들어서 하는 게 좋을까 아니면 같은 설치를 user data 등을 이용해서 하는 게 좋을까? 어떤게 더 비용을 최적화 할 수 있는지 알려줘
- DRAM과 SSD의 속도 비교는 어떻게 할 수 있어?
- SSD 대기 시간
- NVMe SSD기준으로 이야기해줘. 그런데 DRAM은 속도 단위가 MHz이고, SSD는 단위가 MB/s잖아. 어떻게 비교해?
- 왜 3200×64×2에서 왜 2배를 곱해줘?
- 폰 노이만 아키텍처에서 SSD와 같은 저장 공간도 그 아키텍처에 원래 포함이 되는 걸까?
- 3200×64×2 / 8 에서 8비트를 나눠주는 이유
- GPU에는 쿠다 코어가 있잖아? 그런데 이거는 물리적인 실제 코어가 아닌, 물리적 코어를 논리적인 코어로 나눈 것이라고 들었어. 맞을까?
- H100에 대해서 알아?
- H100의 쿠다 코어 수
- 일반적인 GPU와 H100이 뭐가 다를까
- 그럼 일반적인 하드웨어 구조는 동일한 걸까?
- NVLink 및 NVSwitch는 별도의 하드웨어야?
- 하드웨어 기술이라는 건 하드웨어를 말하는 거지?
- 궁금한 게 있어. GPU의 메모리도 RAM일까?
- 그러면, RAM에서 GPU memory로 데이터를 어떻게 전송해?
- Unified Memory에 대해 궁금한 점이 있어. 물리적으로 RAM과 GPU memory는 분리되어 있는데, 어떻게 하나의 메모리 공간을 유지하는 거야? 어디에?
- 그러면 RAM과 GPU memory 각각에 같은 데이터가 읽혀져 있는 상태이고, 같은 데이터에 대한 주소 공간을 소프트웨어가 별도로 저장하고 있다는 거지?
- 궁금한 게 있어. 동영상 스트리밍이나 게임 그래픽은 GPU에서 처리하잖아. 그 데이터는 어떻게 통신하고 연산되는 걸까?
- 데이터 형태는 주소 공간으로 조회할 수 있는 매트릭스와 같은 형태야?
- 내가 이해한 게 맞는지 체크해줘.
  1. 먼저 CPU에서 동영상 데이터를 decoding한 다음, 그 데이터를 GPU memory로 보내. 
  2. GPU 매트릭스와 같은 형태로 연산을 해.
- 그럼 영상의 데이터는 계속 GPU에 남아 있는 거야?
- CPU에서는 순차적으로 프레임 데이터를 저장하고, 그리고 순차적으로 GPU에 보내는 걸까?
- 그런데 말야. 예를 들어 유튜브 영상에서 10분 짜리 영상이 있어. 내가 7분 프레임에서 갑자기 3분 프레임으로 넘어갔어. 그러면 어떻게 돼?
- 여기서 궁금한 게 2가지가 있어.
  1. 3분 지점의 키 프레임을 찾는 작업은 시간복잡도가 어떻게 돼? 그 작동하는 방법. 
  2. 영상은 블록처럼, 예를 들어 몇 분의 프레임은 저장하고 다시 렌더링을 안 하고 바로 보여질 수 있게 하잖아. 이거는 어떻게 하는 거야?
- 캐싱 전략은 게임 그래픽에서도 동일한 원리로 작동하는 거지?
- 오케이.. 키 프레임에 대해 좀 더 궁금해. 예를 들어 100000 프레임이 있어. 근데 키 프레임으로 이 모든 프레임을 저장하는 거야?
- 그런데 머신 러닝에서 매트릭스 계산이랑 동영상 스트리밍에서 데이터 처리 방식이랑 똑같네?
- 좀 더 궁금한 게 있어. GPU는 코어 수가 많기 때문에 한 매트릭스(n x n)를 (코어 수 만큼) 동시에 연산이 가능하다는 거는 알겠어. 맞지?
- 여기서 궁금한 게 있어. 예를 들어서 100 x 100 매트릭스가 있어. 그리고 GPU 코어 수는 이 매트릭스를 한 번에 계산하는 데에 충분한 코어가 있다고 가정하자.<br/>
  그럼 100 x 100의 매트릭스는 동시에 연산이 수행한다고 하더라도 결국 순차적으로 접근해야 하는거 아니야?
- 2번 타일링에 대해 좀 더 자세히 설명해줘. 이 타일들은 **공유 메모리(shared memory)**에 로드된다 부분에서 궁금해. 그럼 각 코어에게도 메모리가 있고, GPU 메모리도 따로 있는 거야?
- 글로벌 메모리는 매트릭스 전체를 저장하고, 공유 메모리는 각 코어에 할당될 데이터들을 매핑하고, 레지스터는 변수를 저장해서 연산하는 작업을 하는 거지?
- 아까 이야기했던 캐시에 대해서 좀 더 알려줘.
  3. 캐시와 공유 메모리를 통한 병렬 접근<br/>
  GPU는 캐시와 공유 메모리를 활용하여 자주 사용하는 데이터는 메모리에서 가져오는 대신, 캐시에 저장하여 빠르게 접근할 수 있습니다.<br/>
  예를 들어, 매트릭스 곱셈에서 한 타일에 대한 연산을 여러 코어가 반복해서 사용해야 하는 경우, 공유 메모리에 로드된 데이터를 코어들이 재사용하여 메모리 접근 시간을 줄입니다.
- 
